---
title: "Machine learning course project"
author: "Siddhesh Amarnath"
date: "20 July 2015"
output: html_document
---

Insert intro here

```{r}
library(caret)
#first loading both training and test data sets
pmlTrainingData<-read.csv("pml-training.csv",na.strings = c("NA", "","#DIV/0!"))
pmlTestingData<-read.csv("pml-testing.csv",na.strings = c("NA", "","#DIV/0!"))
#identifying columns that have any na values
naColumnsTraining<-colSums(is.na(pmlTrainingData))==0
naColumnsTesting<-colSums(is.na(pmlTestingData))==0
#only including the columns that have no NA values
nonNATrainingData<-pmlTrainingData[,naColumnsTraining]
nonNATestingData<-pmlTestingData[,naColumnsTesting]
#excluding the columns that have near zero variability (column 160 is the classe variable, so I am not running nearZeroVar on that)
nzv <- nearZeroVar(nonNATrainingData[,-160])
filteredPMLtraining <- nonNATrainingData[, -nzv]
#exclusing columns such as serial no., timestamps etc that have no effect on the outcome of the exercise performed
filteredPMLtraining<-filteredPMLtraining[,-c(1,3,4,5)]
#configuring parallel computation
library(doParallel)
mc <- makeCluster(detectCores())
registerDoParallel(mc)
set.seed(123)
#creating a subset of training data with 20% of the values
trainIndex20 <- createDataPartition(filteredPMLtraining$classe,
p = 0.2, list = FALSE)
trainset1 <- filteredPMLtraining[trainIndex20,] #has 20% of the whole set
tempset1 <- filteredPMLtraining[-trainIndex20,] #has the remaining 80% of data
#now training the data set to predict the classe using random forests, which is a model building algorithm well suited for classification problems
model1 <- train(classe~.,data=trainset1,method="rf", trControl = trainControl(method="cv",number =3,allowParallel = TRUE))
model1
model1$finalModel
#listing the predictors in order of importance in predicting classe
varImp(model1)
#selecting only the variables with importance >=10 to reduce number of predictors used in the main model generation and prevent overfitting
importance <- varImp(model1)$importance
importance$vars <- rownames(importance)
importance <- importance[order(importance$Overall,
decreasing=TRUE),]
impCols <- importance[(importance$Overall >= 10.0),2]
impCols
#now splitting the remaining 80% of the data into 2 equal halves 
#one for model creation with the reduced number of parameters
#the other for validation
trainIndex50 <- createDataPartition(tempset1$classe,
p = (0.5/0.8), list = FALSE)
trainset2 <- tempset1[trainIndex50,]
validset <- tempset1[-trainIndex50,]
trainset2 <- trainset2[,c(impCols,"classe")]
#now creating the new model using random forests, with the reduced number of parameters
model2 <- train(classe~.,data=trainset2,method="rf", trControl = trainControl(method="cv",
number = 3,allowParallel = TRUE))
model2
model2$finalModel 
#The above result shows that the expected out of sample error for the model is 0.38%
validate <- predict(model2,validset)
confusionMatrix(validate,validset$classe)
#Checking the model output on the test data
answer <- predict(model2,nonNATestingData)
answer
```

